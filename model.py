import torch
import segmentation_models_pytorch as smp
import cv2
import numpy as np
import os

class HumanSegmentator:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ç–æ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, model_path=None, model_type="improved"):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ç–æ—Ä–∞ –Ω–∞ {self.device}")
        
        # –í—ã–±–æ—Ä —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ–¥–µ–ª–∏
        if model_type == "improved" and model_path:
            self.image_size = (512, 512)  # –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            self.model = self._load_improved_model(model_path)
        else:
            self.image_size = (256, 256)  # –ë–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç—å/–∫–∞—á–µ—Å—Ç–≤–æ
            self.model = self._load_basic_model()
        
        self.model.to(self.device)
        self.model.eval()
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        self._optimize_model()
    
    def _load_basic_model(self):
        """–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏"""
        print("‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ (ResNet18)")
        model = smp.Unet(
            encoder_name="resnet18",
            encoder_weights="imagenet",
            classes=1,
            activation="sigmoid"
        )
        return model
    
    def _load_improved_model(self, model_path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        if not os.path.exists(model_path):
            print("‚ö†Ô∏è –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é")
            return self._load_basic_model()
        
        print("‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (ResNet34)")
        model = smp.Unet(
            encoder_name="resnet34",
            encoder_weights=None,  # –ë–µ–∑ –∏–º–ø–µ–π–Ω–µ—Ç –≤–µ—Å–æ–≤, —Ç.–∫. —Å–≤–æ–∏
            classes=1,
            activation="sigmoid"
        )
        
        try:
            model.load_state_dict(torch.load(model_path, map_location=self.device))
            print("üéØ –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")
            return self._load_basic_model()
        
        return model
    
    def _optimize_model(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏"""
        # TorchScript –∫–æ–º–ø–∏–ª—è—Ü–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        try:
            example_input = torch.randn(1, 3, *self.image_size).to(self.device)
            self.model = torch.jit.trace(self.model, example_input)
            print("‚ö° –ú–æ–¥–µ–ª—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å TorchScript")
        except Exception as e:
            print(f"‚ö†Ô∏è TorchScript –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
        
        # –ü–æ–ª–æ–≤–∏–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è GPU
        if self.device.type == 'cuda':
            self.model = self.model.half()
            print("üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–ª–æ–≤–∏–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (FP16)")
    
    def process_image(self, image_path_or_array, background="blue", custom_background=None):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        
        Args:
            image_path_or_array: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∏–ª–∏ numpy array
            background: —Ç–∏–ø —Ñ–æ–Ω–∞ ("blue", "green", "gradient", "black", "blur")
            custom_background: –∫–∞—Å—Ç–æ–º–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ñ–æ–Ω–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
        Returns:
            mask: –±–∏–Ω–∞—Ä–Ω–∞—è –º–∞—Å–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
            result: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–º —Ñ–æ–Ω–æ–º
        """
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if isinstance(image_path_or_array, str):
            image = cv2.imread(image_path_or_array)
            if image is None:
                raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path_or_array}")
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            image = image_path_or_array
        
        original_size = image.shape[:2]
        
        # –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
        processed_image = self._preprocess_image(image)
        mask = self._predict_mask(processed_image)
        final_mask = self._postprocess_mask(mask, original_size)
        
        # –ó–∞–º–µ–Ω–∞ —Ñ–æ–Ω–∞
        result = self._apply_background(image, final_mask, background, custom_background)
        
        return final_mask, result
    
    def _preprocess_image(self, image):
        """–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
        image_resized = cv2.resize(image, self.image_size)
        image_normalized = image_resized.astype(np.float32) / 255.0
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ç–µ–Ω–∑–æ—Ä
        image_tensor = torch.from_numpy(image_resized).permute(2, 0, 1).unsqueeze(0)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è ImageNet
        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)
        image_tensor = (image_tensor.float() / 255.0 - mean) / std
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –ø–æ–ª–æ–≤–∏–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –µ—Å–ª–∏ –Ω–∞ GPU
        if self.device.type == 'cuda':
            image_tensor = image_tensor.half()
        else:
            image_tensor = image_tensor.float()
            
        return image_tensor.to(self.device)
    
    def _predict_mask(self, image_tensor):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å–∫–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é"""
        with torch.no_grad():
            output = self.model(image_tensor)
            mask = torch.sigmoid(output)  # –ê–∫—Ç–∏–≤–∞—Ü–∏—è —Å–∏–≥–º–æ–∏–¥–æ–π
            mask = mask.squeeze().cpu().numpy()
        return mask
    
    def _postprocess_mask(self, mask, original_size):
        """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —É–ª—É—á—à–µ–Ω–∏–µ –º–∞—Å–∫–∏"""
        # –†–µ—Å–∞–π–∑ –¥–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        mask_resized = cv2.resize(mask, (original_size[1], original_size[0]))
        
        # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
        binary_mask = (mask_resized > 0.5).astype(np.uint8) * 255
        
        # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
        kernel = np.ones((5, 5), np.uint8)
        
        # –ó–∞–∫—Ä—ã—Ç–∏–µ (–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –º–∞–ª–µ–Ω—å–∫–∏—Ö –¥—ã—Ä–æ–∫)
        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)
        
        # –û—Ç–∫—Ä—ã—Ç–∏–µ (—É–¥–∞–ª–µ–Ω–∏–µ –º–∞–ª–µ–Ω—å–∫–∏—Ö —à—É–º–æ–≤)
        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)
        
        # –†–∞–∑–º—ã—Ç–∏–µ –≥—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
        binary_mask = cv2.GaussianBlur(binary_mask, (5, 5), 0)
        binary_mask = (binary_mask > 128).astype(np.uint8) * 255
        
        return binary_mask
    
    def _apply_background(self, image, mask, background_type, custom_background=None):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ñ–æ–Ω–∞ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é"""
        if custom_background is not None:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π —Ñ–æ–Ω
            if isinstance(custom_background, str):
                background = cv2.imread(custom_background)
                background = cv2.cvtColor(background, cv2.COLOR_BGR2RGB)
            else:
                background = custom_background
            
            # –†–µ—Å–∞–π–∑ —Ñ–æ–Ω–∞ –ø–æ–¥ —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if background.shape[:2] != image.shape[:2]:
                background = cv2.resize(background, (image.shape[1], image.shape[0]))
        else:
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–æ–Ω–∞ –ø–æ —Ç–∏–ø—É
            background = self._generate_background(image.shape, background_type)
        
        # –°–æ–∑–¥–∞–µ–º –ø–ª–∞–≤–Ω—É—é –º–∞—Å–∫—É –¥–ª—è –∫—Ä–∞–µ–≤
        smooth_mask = mask.astype(np.float32) / 255.0
        smooth_mask = cv2.GaussianBlur(smooth_mask, (7, 7), 0)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å–∫—É —Å –ø–ª–∞–≤–Ω—ã–º–∏ –∫—Ä–∞—è–º–∏
        if len(smooth_mask.shape) == 2:
            smooth_mask = np.stack([smooth_mask] * 3, axis=2)
        
        result = image * smooth_mask + background * (1 - smooth_mask)
        return result.astype(np.uint8)
    
    def _generate_background(self, image_shape, background_type):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–æ–Ω–∞ –ø–æ —Ç–∏–ø—É"""
        h, w = image_shape[:2]
        
        if background_type == "blue":
            background = np.full((h, w, 3), [255, 0, 0], dtype=np.uint8)  # –°–∏–Ω–∏–π –≤ RGB
        elif background_type == "green":
            background = np.full((h, w, 3), [0, 255, 0], dtype=np.uint8)  # –ó–µ–ª–µ–Ω—ã–π
        elif background_type == "black":
            background = np.zeros((h, w, 3), dtype=np.uint8)  # –ß–µ—Ä–Ω—ã–π
        elif background_type == "blur":
            # –†–∞–∑–º—ã—Ç–∞—è –≤–µ—Ä—Å–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞–∫ —Ñ–æ–Ω
            background = cv2.GaussianBlur(np.zeros((h, w, 3)), (51, 51), 0)
        elif background_type == "gradient":
            background = self._create_gradient_background((h, w))
        else:
            # –ì—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            background = self._create_gradient_background((h, w))
        
        return background
    
    def _create_gradient_background(self, size):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Ñ–æ–Ω–∞"""
        h, w = size
        background = np.zeros((h, w, 3), dtype=np.uint8)
        
        for i in range(h):
            # –°–∏–Ω–∏–π -> –§–∏–æ–ª–µ—Ç–æ–≤—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç
            progress = i / h
            blue = int(255 * (1 - progress))
            red = int(255 * progress)
            green = int(128 * abs(np.sin(progress * 3.14)))
            background[i, :] = [blue, green, red]
        
        return background
    
    def batch_process(self, image_paths, background="blue", output_dir="outputs"):
        """–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        os.makedirs(output_dir, exist_ok=True)
        results = []
        
        for i, image_path in enumerate(image_paths):
            try:
                mask, result = self.process_image(image_path, background)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                base_name = os.path.basename(image_path).split('.')[0]
                result_path = os.path.join(output_dir, f"{base_name}_result.jpg")
                mask_path = os.path.join(output_dir, f"{base_name}_mask.png")
                
                cv2.imwrite(result_path, cv2.cvtColor(result, cv2.COLOR_RGB2BGR))
                cv2.imwrite(mask_path, mask)
                
                results.append({
                    'input': image_path,
                    'result': result_path,
                    'mask': mask_path
                })
                
                print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i+1}/{len(image_paths)}: {base_name}")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {image_path}: {e}")
        
        return results

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
def test_model():
    """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –º–æ–¥–µ–ª–∏"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    test_img = np.ones((300, 200, 3), dtype=np.uint8) * 255
    cv2.rectangle(test_img, (50, 50), (150, 250), (100, 100, 100), -1)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞
    segmentator = HumanSegmentator()
    mask, result = segmentator.process_image(test_img, "gradient")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    cv2.imwrite("test_input.jpg", test_img)
    cv2.imwrite("test_mask.jpg", mask)
    cv2.imwrite("test_result.jpg", cv2.cvtColor(result, cv2.COLOR_RGB2BGR))
    
    print("‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å —Ñ–∞–π–ª—ã test_*.jpg")

if __name__ == "__main__":
    test_model()